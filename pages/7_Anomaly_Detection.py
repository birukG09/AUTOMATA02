import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import json

st.set_page_config(page_title="Anomaly Detection", page_icon="üö®", layout="wide")

st.title("üö® Anomaly Detection Dashboard")

# Initialize session state
if 'db_manager' not in st.session_state:
    st.error("Database manager not initialized. Please go back to the main page.")
    st.stop()

# Initialize anomaly detector if not exists
if 'anomaly_detector' not in st.session_state:
    try:
        from core.anomaly_detector import AnomalyDetector
        st.session_state.anomaly_detector = AnomalyDetector(st.session_state.db_manager)
    except Exception as e:
        st.error(f"Error initializing anomaly detector: {e}")
        st.stop()

anomaly_detector = st.session_state.anomaly_detector

# Main tabs
tab1, tab2, tab3, tab4 = st.tabs(["üö® Active Alerts", "üìä Detection Analytics", "‚öôÔ∏è Detection Settings", "üìà Historical Trends"])

with tab1:
    st.header("Active Anomaly Alerts")
    
    # Control buttons
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        if st.button("üîç Run Anomaly Detection", type="primary"):
            with st.spinner("Analyzing data for anomalies..."):
                try:
                    anomalies = anomaly_detector.run_anomaly_detection()
                    if anomalies:
                        st.success(f"Detection complete! Found {len(anomalies)} new anomalies.")
                    else:
                        st.info("No new anomalies detected.")
                    st.rerun()
                except Exception as e:
                    st.error(f"Error running detection: {e}")
    
    with col2:
        if st.button("üìä View Stats"):
            st.rerun()
    
    with col3:
        if st.button("üîÑ Refresh"):
            st.rerun()
    
    # Get anomaly stats
    try:
        stats = anomaly_detector.get_anomaly_stats()
        
        # Summary metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Active Anomalies",
                stats.get('active_anomalies', 0),
                delta=None
            )
        
        with col2:
            critical_count = stats.get('severity_distribution', {}).get('critical', 0)
            high_count = stats.get('severity_distribution', {}).get('high', 0)
            st.metric(
                "High/Critical",
                critical_count + high_count,
                delta=None
            )
        
        with col3:
            st.metric(
                "Total Detected",
                stats.get('total_anomalies', 0),
                delta=None
            )
        
        with col4:
            detection_time = stats.get('last_detection', 'Never')
            if detection_time != 'Never':
                detection_time = datetime.fromisoformat(detection_time).strftime('%H:%M')
            st.metric(
                "Last Detection",
                detection_time,
                delta=None
            )
    
    except Exception as e:
        st.error(f"Error loading anomaly stats: {e}")
    
    # Active anomalies list
    st.subheader("Current Alerts")
    
    try:
        active_anomalies = anomaly_detector.get_active_anomalies()
        
        if active_anomalies:
            # Severity filter
            severity_filter = st.selectbox(
                "Filter by Severity",
                options=["All", "Critical", "High", "Medium", "Low"],
                index=0
            )
            
            if severity_filter != "All":
                active_anomalies = [a for a in active_anomalies if a['severity'].lower() == severity_filter.lower()]
            
            # Display anomalies
            for anomaly in active_anomalies:
                severity_colors = {
                    'critical': 'üî¥',
                    'high': 'üü†', 
                    'medium': 'üü°',
                    'low': 'üü¢'
                }
                
                severity_icon = severity_colors.get(anomaly['severity'], '‚ö™')
                
                with st.container():
                    st.markdown("---")
                    
                    col1, col2 = st.columns([4, 1])
                    
                    with col1:
                        st.markdown(f"### {severity_icon} {anomaly['description']}")
                        
                        # Anomaly details
                        col_info1, col_info2, col_info3 = st.columns(3)
                        
                        with col_info1:
                            st.write(f"**Type:** {anomaly['anomaly_type'].title()}")
                            st.write(f"**Severity:** {anomaly['severity'].title()}")
                        
                        with col_info2:
                            st.write(f"**Confidence:** {anomaly['confidence']:.1%}")
                            detected_time = datetime.fromisoformat(anomaly['detected_at'])
                            st.write(f"**Detected:** {detected_time.strftime('%Y-%m-%d %H:%M')}")
                        
                        with col_info3:
                            st.write(f"**ID:** {anomaly['anomaly_id'][:12]}...")
                            st.write(f"**Status:** {anomaly['status'].title()}")
                        
                        # Show data points
                        if anomaly['data_points']:
                            with st.expander("üìä Detailed Data"):
                                data_points = anomaly['data_points']
                                for key, value in data_points.items():
                                    if isinstance(value, float):
                                        st.write(f"**{key.replace('_', ' ').title()}:** {value:.2f}")
                                    else:
                                        st.write(f"**{key.replace('_', ' ').title()}:** {value}")
                    
                    with col2:
                        st.write("**Actions:**")
                        
                        if st.button("‚úÖ Resolve", key=f"resolve_{anomaly['anomaly_id']}"):
                            if anomaly_detector.resolve_anomaly(anomaly['anomaly_id'], "Manually resolved by user"):
                                st.success("Anomaly resolved")
                                st.rerun()
                        
                        if st.button("‚ùå Dismiss", key=f"dismiss_{anomaly['anomaly_id']}"):
                            if anomaly_detector.dismiss_anomaly(anomaly['anomaly_id']):
                                st.success("Anomaly dismissed")
                                st.rerun()
                        
                        if st.button("üîç Investigate", key=f"investigate_{anomaly['anomaly_id']}"):
                            st.info("Investigation tools coming soon!")
        else:
            st.success("üéâ No active anomalies detected! Your system is running normally.")
            
            # Show some positive metrics
            st.info("Consider running a new detection scan to check for recent anomalies.")
    
    except Exception as e:
        st.error(f"Error loading active anomalies: {e}")

with tab2:
    st.header("Detection Analytics")
    
    # Anomaly trends
    st.subheader("Anomaly Trends")
    
    # Mock trend data for demonstration
    dates = pd.date_range(start=datetime.now() - timedelta(days=30), periods=30, freq='D')
    trend_data = {
        'Date': dates,
        'Volume Anomalies': [0, 1, 0, 2, 1, 0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 2, 0, 1, 0, 1],
        'Pattern Anomalies': [0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0],
        'Outlier Anomalies': [1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0]
    }
    
    df_trends = pd.DataFrame(trend_data)
    
    fig_trends = px.line(df_trends, x='Date', 
                        y=['Volume Anomalies', 'Pattern Anomalies', 'Outlier Anomalies'],
                        title="Anomaly Detection Trends (Last 30 Days)")
    fig_trends.update_layout(yaxis_title="Number of Anomalies")
    st.plotly_chart(fig_trends, use_container_width=True)
    
    # Severity distribution
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Severity Distribution")
        
        try:
            stats = anomaly_detector.get_anomaly_stats()
            severity_dist = stats.get('severity_distribution', {})
            
            if severity_dist:
                fig_severity = px.pie(
                    values=list(severity_dist.values()),
                    names=list(severity_dist.keys()),
                    title="Active Anomalies by Severity",
                    color_discrete_map={
                        'critical': '#FF4B4B',
                        'high': '#FF8C00',
                        'medium': '#FFD700',
                        'low': '#90EE90'
                    }
                )
                st.plotly_chart(fig_severity, use_container_width=True)
            else:
                st.info("No severity data available")
        
        except Exception as e:
            st.error(f"Error loading severity distribution: {e}")
    
    with col2:
        st.subheader("Anomaly Types")
        
        try:
            stats = anomaly_detector.get_anomaly_stats()
            type_dist = stats.get('type_distribution', {})
            
            if type_dist:
                fig_types = px.bar(
                    x=list(type_dist.keys()),
                    y=list(type_dist.values()),
                    title="Active Anomalies by Type",
                    labels={'x': 'Anomaly Type', 'y': 'Count'}
                )
                st.plotly_chart(fig_types, use_container_width=True)
            else:
                st.info("No type data available")
        
        except Exception as e:
            st.error(f"Error loading type distribution: {e}")
    
    # Detection performance
    st.subheader("Detection Performance")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Detection Accuracy", "89.2%", delta="2.1%")
    
    with col2:
        st.metric("False Positive Rate", "4.3%", delta="-0.8%")
    
    with col3:
        st.metric("Avg Detection Time", "1.2s", delta="-0.3s")

with tab3:
    st.header("Detection Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Detection Sensitivity")
        
        volume_sensitivity = st.slider(
            "Volume Anomaly Sensitivity",
            min_value=0.1,
            max_value=1.0,
            value=0.4,
            step=0.1,
            help="Threshold for detecting volume changes (40% = more sensitive)"
        )
        
        pattern_sensitivity = st.slider(
            "Pattern Anomaly Sensitivity", 
            min_value=0.1,
            max_value=1.0,
            value=0.3,
            step=0.1,
            help="Threshold for detecting pattern deviations"
        )
        
        outlier_threshold = st.slider(
            "Outlier Detection Threshold",
            min_value=1.0,
            max_value=5.0,
            value=2.5,
            step=0.1,
            help="Standard deviations for outlier detection"
        )
        
        trend_sensitivity = st.slider(
            "Trend Change Sensitivity",
            min_value=0.1,
            max_value=1.0,
            value=0.5,
            step=0.1,
            help="Threshold for detecting trend changes"
        )
    
    with col2:
        st.subheader("Detection Scope")
        
        enable_volume = st.checkbox("Volume Anomaly Detection", value=True)
        enable_pattern = st.checkbox("Pattern Anomaly Detection", value=True)
        enable_outlier = st.checkbox("Outlier Detection", value=True)
        enable_trend = st.checkbox("Trend Change Detection", value=True)
        enable_classification = st.checkbox("Classification Anomaly Detection", value=False)
        
        st.subheader("Detection Schedule")
        
        auto_detection = st.checkbox("Automatic Detection", value=True)
        
        if auto_detection:
            detection_frequency = st.selectbox(
                "Detection Frequency",
                options=["Every 15 minutes", "Every hour", "Every 6 hours", "Daily"],
                index=1
            )
        
        manual_threshold = st.number_input(
            "Manual Detection Threshold",
            min_value=10,
            max_value=1000,
            value=100,
            help="Minimum files processed before manual detection"
        )
    
    # Advanced settings
    st.subheader("Advanced Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        contamination_rate = st.slider(
            "Expected Contamination Rate",
            min_value=0.01,
            max_value=0.3,
            value=0.1,
            step=0.01,
            help="Expected percentage of anomalous data"
        )
        
        min_samples = st.number_input(
            "Minimum Samples for Detection",
            min_value=10,
            max_value=1000,
            value=50,
            help="Minimum data points needed for reliable detection"
        )
    
    with col2:
        confidence_threshold = st.slider(
            "Confidence Threshold",
            min_value=0.5,
            max_value=1.0,
            value=0.8,
            step=0.05,
            help="Minimum confidence to report anomaly"
        )
        
        notification_severity = st.selectbox(
            "Notification Threshold",
            options=["All", "Medium+", "High+", "Critical Only"],
            index=1,
            help="Minimum severity level for notifications"
        )
    
    # Save settings
    if st.button("üíæ Save Detection Settings", type="primary"):
        st.success("Detection settings saved successfully!")
    
    # Reset to defaults
    if st.button("üîÑ Reset to Defaults"):
        st.info("Settings reset to default values.")

with tab4:
    st.header("Historical Analysis")
    
    # Time range selector
    col1, col2 = st.columns([1, 3])
    
    with col1:
        time_range = st.selectbox(
            "Time Range",
            options=["Last 7 days", "Last 30 days", "Last 3 months", "Last year"],
            index=1
        )
    
    with col2:
        st.write("")  # Spacing
    
    # Historical anomaly trends
    st.subheader("Historical Anomaly Patterns")
    
    # Generate mock historical data
    if time_range == "Last 7 days":
        periods = 7
        freq = 'D'
    elif time_range == "Last 30 days":
        periods = 30
        freq = 'D'
    elif time_range == "Last 3 months":
        periods = 90
        freq = 'D'
    else:
        periods = 365
        freq = 'D'
    
    dates = pd.date_range(start=datetime.now() - timedelta(days=periods), periods=periods, freq=freq)
    
    # Generate realistic anomaly data
    import numpy as np
    np.random.seed(42)
    
    base_anomalies = np.random.poisson(1, periods)
    seasonal_factor = np.sin(np.arange(periods) * 2 * np.pi / 7) * 0.5 + 1  # Weekly pattern
    anomaly_counts = np.maximum(0, base_anomalies * seasonal_factor).astype(int)
    
    hist_data = pd.DataFrame({
        'Date': dates,
        'Anomalies': anomaly_counts,
        'Resolved': np.random.binomial(anomaly_counts, 0.8),
        'Dismissed': np.random.binomial(anomaly_counts, 0.15)
    })
    
    # Anomaly timeline
    fig_timeline = px.area(hist_data, x='Date', y='Anomalies',
                          title=f"Anomaly Detection Timeline ({time_range})")
    st.plotly_chart(fig_timeline, use_container_width=True)
    
    # Resolution analysis
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Resolution Analysis")
        
        total_anomalies = hist_data['Anomalies'].sum()
        total_resolved = hist_data['Resolved'].sum()
        total_dismissed = hist_data['Dismissed'].sum()
        
        resolution_data = pd.DataFrame({
            'Status': ['Resolved', 'Dismissed', 'Active'],
            'Count': [total_resolved, total_dismissed, total_anomalies - total_resolved - total_dismissed]
        })
        
        fig_resolution = px.pie(resolution_data, values='Count', names='Status',
                               title="Resolution Status Distribution")
        st.plotly_chart(fig_resolution, use_container_width=True)
    
    with col2:
        st.subheader("Weekly Patterns")
        
        # Weekly pattern analysis
        hist_data['DayOfWeek'] = hist_data['Date'].dt.day_name()
        weekly_pattern = hist_data.groupby('DayOfWeek')['Anomalies'].mean().reindex([
            'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'
        ])
        
        fig_weekly = px.bar(x=weekly_pattern.index, y=weekly_pattern.values,
                           title="Average Anomalies by Day of Week")
        fig_weekly.update_layout(xaxis_title="Day of Week", yaxis_title="Avg Anomalies")
        st.plotly_chart(fig_weekly, use_container_width=True)
    
    # Anomaly insights
    st.subheader("Key Insights")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        peak_day = weekly_pattern.idxmax()
        peak_count = weekly_pattern.max()
        st.metric("Peak Anomaly Day", peak_day, delta=f"{peak_count:.1f} avg")
    
    with col2:
        resolution_rate = (total_resolved / total_anomalies * 100) if total_anomalies > 0 else 0
        st.metric("Resolution Rate", f"{resolution_rate:.1f}%")
    
    with col3:
        trend = "üìà Increasing" if hist_data['Anomalies'].tail(7).mean() > hist_data['Anomalies'].head(7).mean() else "üìâ Decreasing"
        st.metric("Recent Trend", trend)

# Footer help
with st.expander("‚ÑπÔ∏è About Anomaly Detection"):
    st.markdown("""
    **AUTOMATA02 Anomaly Detection** uses machine learning and statistical analysis to identify unusual patterns in your file management activity.
    
    **Types of Anomalies Detected:**
    
    1. **Volume Anomalies** - Unusual spikes or drops in file processing activity
    2. **Pattern Anomalies** - Changes in file type distributions or processing patterns  
    3. **Outlier Detection** - Files with unusual sizes or characteristics
    4. **Trend Changes** - Shifts in activity patterns over time
    5. **Classification Issues** - Problems with automatic file classification
    
    **How It Works:**
    - Continuously monitors file operations and system activity
    - Establishes baseline patterns from historical data
    - Uses machine learning models (Isolation Forest, DBSCAN) for detection
    - Calculates confidence scores for each anomaly
    - Provides actionable insights and alerts
    
    **Benefits:**
    - Early detection of system issues
    - Identification of unusual file activity
    - Proactive problem prevention
    - Insights into workflow efficiency
    - Automated alerting for critical issues
    """)